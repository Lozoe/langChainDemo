{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3d09b90-d38d-4e9e-8966-d2ac37c1a29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4923e703cd43ccaf8c9b26c5204fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144e2c2243484f08aac7d843f8bff6ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/421M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313a477ee8fe4f7c9886857a48fe1c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76912f54d3f6455995c59c58f016a083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9915c806d1e8406f89201e0807054859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/421M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00247d12dde6446ca5a180660f97a71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在一个风雨交加的夜晚，程序员小李打开了电脑，突然 袭 击 了 一 条 短 信 ， 说 ： 大 意 是 ， 程 序 员 小 李 ， 想 想 自 己 以 前 也 发 过 类 似 命 令 。 但 是 你 不 要 着 急 啊 ， 看 下 你 要 点 别 的 ， 他 给 你 一 个 小 招 ， 让 你 改 改 命 名 ！ 小 李 第 一 反 应 就 是\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "os.environ[\"HF_HOME\"] = \"/root/autodl-tmp/models\"  # 同时控制 model 和 tokenizer 缓存\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\n",
    "    task=\"text-generation\", \n",
    "    model=\"uer/gpt2-chinese-cluecorpussmall\",\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "text = \"在一个风雨交加的夜晚，程序员小李打开了电脑，突然\"\n",
    "result = generator(text, max_length=100, truncation=True, do_sample=True)\n",
    "print(result[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
