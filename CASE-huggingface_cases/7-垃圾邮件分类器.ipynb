{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b8da7ba2-e325-4e62-85d2-220c8226a942",
      "metadata": {},
      "source": [
        "## Step1，准备环境与数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2427f61e-5f18-47ed-9431-bf8c1810806f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-03 22:41:31.502924: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-02-03 22:41:31.514647: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1770129691.530598   85342 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1770129691.535298   85342 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1770129691.548049   85342 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770129691.548067   85342 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770129691.548069   85342 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770129691.548070   85342 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-03 22:41:31.552629: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# 必须在导入 pipeline 之前设置\n",
        "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
        "os.environ[\"HF_HOME\"] = \"/root/autodl-tmp/models\"  # 同时控制 model 和 tokenizer 缓存\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "\n",
        "# 1. 模拟一个私有数据集 (真实场景用 load_dataset 加载 CSV)\n",
        "data = [\n",
        "    {\"text\": \"今晚有空一起吃饭吗？\", \"label\": 0},  # 正常\n",
        "    {\"text\": \"恭喜您获得500万大奖，点击领取\", \"label\": 1}, # 垃圾\n",
        "    {\"text\": \"您的验证码是1234，请勿泄露\", \"label\": 0},\n",
        "    {\"text\": \"澳门首家线上赌场上线啦\", \"label\": 1},\n",
        "    {\"text\": \"项目进度怎么样了？需不需要开会\", \"label\": 0},\n",
        "    {\"text\": \"独家内幕消息，股票必涨，加群\", \"label\": 1},\n",
        "]\n",
        "# 转为 HF Dataset 对象\n",
        "dataset = Dataset.from_list(data)\n",
        "\n",
        "# 2. 划分训练集和测试集\n",
        "dataset = dataset.train_test_split(test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "439b06dd-8b19-4809-9a69-23086f92b101",
      "metadata": {},
      "source": [
        "## Step2：数据预处理 (Map & Tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b26485fb-5b40-4984-afdb-747c4e49bd68",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6429debf49b24bb39998f1661ca1a80f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e010ff27a85d4da7bcd12b31652eff73",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "checkpoint = \"bert-base-chinese\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    # Truncation=True: 截断过长的\n",
        "    # Padding=False: 这里先不补齐！留给 DataCollator 动态补齐\n",
        "    return tokenizer(examples[\"text\"], truncation=True, max_length=128)\n",
        "\n",
        "# 批量处理\n",
        "tokenized_datasets = dataset.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93671d6b-d598-4ce7-af45-364643197856",
      "metadata": {},
      "source": [
        "## Step3：DataCollator 与 模型加载"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "08f26824-da8b-4756-9c3f-85b58818edea",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "# 动态补齐工具\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# 加载带分类头的模型 (num_labels=2: 二分类)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4198da1-3bc9-403c-96c5-207820207d2e",
      "metadata": {},
      "source": [
        "## Step4：定义评估指标"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9cd64b97-291f-4183-860e-89c1cfb9fc5a",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import evaluate # pip install evaluate\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfcdd629-04cb-4ff2-9b08-393f0fc247d2",
      "metadata": {},
      "source": [
        "## Step5：配置参数并开始训练"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9f95f624-29b7-48ff-9063-12f172fe39a0",
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./spam-bert-finetuned\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 模型保存路径\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 每个 epoch 结束后评估一次\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# 每个 epoch 结束后保存一次\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# 学习率 (微调通常很小)\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# 批次大小 (显存小就调小)\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# 训练轮数\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     13\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     14\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 开始训练！\u001b[39;00m\n",
            "\u001b[0;31mTypeError\u001b[0m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./spam-bert-finetuned\", # 模型保存路径\n",
        "    eval_strategy=\"epoch\",               # 每个 epoch 结束后评估一次\n",
        "    save_strategy=\"epoch\",               # 每个 epoch 结束后保存一次\n",
        "    learning_rate=2e-5,                  # 学习率 (微调通常很小)\n",
        "    per_device_train_batch_size=4,       # 批次大小 (显存小就调小)\n",
        "    num_train_epochs=3,                  # 训练轮数\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# 开始训练！\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aff4c287-88ce-4025-80c9-0f2b15f5266c",
      "metadata": {},
      "source": [
        "## Step6：模型推理 (验证效果)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f503c9d-4bb6-4636-be69-48978d8a9d44",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 模拟一条新数据\n",
        "text = \"低息贷款，无抵押，秒到账\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\").to(model.device) # 确保数据也在 GPU 上\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits\n",
        "    predicted_class_id = logits.argmax().item()\n",
        "\n",
        "print(f\"输入文本: {text}\")\n",
        "print(f\"预测类别: {'垃圾邮件' if predicted_class_id == 1 else '正常邮件'}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
